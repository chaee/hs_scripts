{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1478c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'language', 'source'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pd.read_csv('formatted/sarkar2021en.csv', lineterminator='\\n', sep='\\t')\n",
    "print(df.head())\n",
    "'''\n",
    "files = ['formatted/chung2019.csv', 'formatted/chung2021.csv', 'formatted/fanton2021.csv', 'formatted/samory2021en.csv', 'formatted/sarkar2021en.csv']\n",
    "\n",
    "df = pd.read_csv('formatted/formatted.csv', lineterminator='\\n', sep='\\t',delimiter=None)\n",
    "df = df[df.language=='en']\n",
    "df.loc[:, \"source\"] = df[\"source\"].apply(lambda x : x[:-4])\n",
    "    \n",
    "df.source.unique()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "484d6556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ousidhoum2019en_with_stopwords' 'ousidhoum2019en' 'davidson2017en'\n",
      " 'gibert2018en' 'gao2018en' 'qian2019en_gab' 'qian2019en_reddit'\n",
      " 'chung2019' 'chung2021' 'fanton2021' 'samory2021en' 'sarkar2021en']\n",
      "['en']\n"
     ]
    }
   ],
   "source": [
    "dfs = list()\n",
    "ssum=0\n",
    "\n",
    "for ds in files:\n",
    "    dfi = pd.read_csv(ds, lineterminator='\\n', sep='\\t', skiprows=0, delimiter=None)\n",
    "    dfi = dfi[dfi.language=='en']\n",
    "    dfs.append(dfi)\n",
    "    #print(dfi.text.count)\n",
    "    ssum += len(dfi)\n",
    "merged = pd.concat(dfs, axis=0)\n",
    "#print(merged.source.unique())\n",
    "merged = pd.concat([df, merged], axis=0)\n",
    "print(merged.source.unique())\n",
    "print(merged.language.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0029ed93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ousidhoum2019en_with_stopwords', 'ousidhoum2019en',\n",
       "       'davidson2017en', 'gibert2018en', 'gao2018en', 'qian2019en_gab',\n",
       "       'qian2019en_reddit', 'chung2019', 'chung2021', 'fanton2021',\n",
       "       'samory2021en', 'sarkar2021en'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e5c8582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ousidhoum2019en_with_stopwords', 'ousidhoum2019en',\n",
       "       'davidson2017en', 'gibert2018en', 'gao2018en', 'qian2019en_gab',\n",
       "       'qian2019en_reddit', 'chung2019', 'chung2021', 'fanton2021',\n",
       "       'samory2021en', 'sarkar2021en'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.to_csv('formatted/merged.csv', index=False, sep='\\t')\n",
    "df = pd.read_csv('formatted/merged.csv', lineterminator='\\n', sep='\\t')\n",
    "df.source.unique()\n",
    "#df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9245b0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        128309\n",
       "label       128309\n",
       "language    128309\n",
       "source      128309\n",
       "dataset      13631\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25156660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- formatted/chung2019.csv -------\n",
      "Index(['text', 'label', 'language', 'source'], dtype='object')\n",
      "                                                text                label  \\\n",
      "0  According to a recent OFSTED report, a school ...  Islamophobia,crimes   \n",
      "1  In Birmingham there is a school where girls an...  Islamophobia,crimes   \n",
      "2  A school in Birningham is still separating gir...  Islamophobia,crimes   \n",
      "3  According to a recent OFSTED report, a school ...  Islamophobia,crimes   \n",
      "4  In Birmingham there is a school where girls an...  Islamophobia,crimes   \n",
      "\n",
      "  language     source  \n",
      "0       en  chung2019  \n",
      "1       en  chung2019  \n",
      "2       en  chung2019  \n",
      "3       en  chung2019  \n",
      "4       en  chung2019  \n",
      "------- formatted/chung2021.csv -------\n",
      "Index(['text', 'label', 'language', 'source'], dtype='object')\n",
      "                                                text         label language  \\\n",
      "0                Jews are selfish, cheap and greedy.  Antisemitism       en   \n",
      "1                           Jews are Christ Killers.  Antisemitism       en   \n",
      "2  Go and reat the Protocols of the elders of Zio...  Antisemitism       en   \n",
      "3  Go and reat the Protocols of the elders of Zio...  Antisemitism       en   \n",
      "4  Go and reat the Protocols of the elders of Zio...  Antisemitism       en   \n",
      "\n",
      "      source  \n",
      "0  chung2021  \n",
      "1  chung2021  \n",
      "2  chung2021  \n",
      "3  chung2021  \n",
      "4  chung2021  \n",
      "------- formatted/fanton2021.csv -------\n",
      "Index(['text', 'label', 'language', 'source'], dtype='object')\n",
      "                                                text  \\\n",
      "0  Maybe the UN could talk to those asian and afr...   \n",
      "1  ‘Juice (Jews) are worse that nukes.’ Caption t...   \n",
      "2  Foreigners on UK benefits leaps 41% in 5 years...   \n",
      "3  Jews cannot be patriots, since their allegianc...   \n",
      "4  Israel, Zionism and Jewish Supremacist control...   \n",
      "\n",
      "                                               label language      source  \n",
      "0  You're right, ocean pollution is one of the ma...       en  fanton2021  \n",
      "1                   You'd rather be nuked then?,JEWS       en  fanton2021  \n",
      "2  You seem to be worried about government expend...       en  fanton2021  \n",
      "3  You can have parents and grandparents born els...       en  fanton2021  \n",
      "4  Wouldn't you say its colonialism from many dif...       en  fanton2021  \n",
      "------- formatted/samory2021en.csv -------\n",
      "Index(['text', 'label', 'language', 'source', 'dataset'], dtype='object')\n",
      "                                                text              label  \\\n",
      "0  MENTION3481 i didn't even know random was an o...  0.118180156,False   \n",
      "1                   Bottom two should've gone!  #mkr   0.25184965,False   \n",
      "2  MENTION3111 MENTION3424 ladyboner deserves so ...   0.11333082,False   \n",
      "3  She shall now be known as Sourpuss #MKR #KatAn...   0.53115267,False   \n",
      "4  Tarah W threw a bunch of women under the bus s...   0.11871842,False   \n",
      "\n",
      "  language        source dataset  \n",
      "0       en  samory2021en   other  \n",
      "1       en  samory2021en   other  \n",
      "2       en  samory2021en  callme  \n",
      "3       en  samory2021en   other  \n",
      "4       en  samory2021en   other  \n",
      "------- formatted/sarkar2021en.csv -------\n",
      "Index(['text', 'label', 'language', 'source'], dtype='object')\n",
      "                                                text         label language  \\\n",
      "0  12:56 Even stockfish gets pinned by the knight...  benign chess       en   \n",
      "1  Some people just want to see chess die out, pe...  benign chess       en   \n",
      "2  Bd7 by black is a mistake.  It allows white to...  benign chess       en   \n",
      "3  After the opening, around 15 Qf4, it seems whi...  benign chess       en   \n",
      "4  I just now finally understood what alpha zero ...  benign chess       en   \n",
      "\n",
      "         source  \n",
      "0  sarkar2021en  \n",
      "1  sarkar2021en  \n",
      "2  sarkar2021en  \n",
      "3  sarkar2021en  \n",
      "4  sarkar2021en  \n"
     ]
    }
   ],
   "source": [
    "for ds in files:\n",
    "    print('-------',ds,'-------')\n",
    "    ndf = pd.read_csv(ds, lineterminator='\\n', sep='\\t', skiprows=0, delimiter=None) \n",
    "    print(ndf.columns)\n",
    "    #ndf = ndf[ndf.language=='en']\n",
    "    print(ndf.head())\n",
    "    \n",
    "    df = pd.concat([df, ndf], verify_integrity=True, axis=0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff7378c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ousidhoum2019en_with_stopwords', 'ousidhoum2019en',\n",
       "       'davidson2017en', 'gibert2018en', 'gao2018en', 'qian2019en_gab',\n",
       "       'qian2019en_reddit', 'chung2019', 'chung2021', 'fanton2021',\n",
       "       'samory2021en', 'sarkar2021en'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c124c800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ousidhoum2019en_with_stopwords', 'ousidhoum2019en',\n",
       "       'davidson2017en', 'gibert2018en', 'gao2018en', 'qian2019en_gab',\n",
       "       'qian2019en_reddit', 'chung2019', 'chung2021', 'fanton2021',\n",
       "       'samory2021en', 'sarkar2021en'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8919c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('formatted/merged.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d6b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If America had another 8 years of Obama's ideo...</td>\n",
       "      <td>['disrespectful', 'none', 'fearful', 'hate', '...</td>\n",
       "      <td>en</td>\n",
       "      <td>ousidhoum2019en_with_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most Canadians have never met seen or associat...</td>\n",
       "      <td>['offensive', 'indirect']</td>\n",
       "      <td>en</td>\n",
       "      <td>ousidhoum2019en_with_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hahaha grow up faggot @URL</td>\n",
       "      <td>['offensive', 'indirect']</td>\n",
       "      <td>en</td>\n",
       "      <td>ousidhoum2019en_with_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user queue is fucking retarded it makes every...</td>\n",
       "      <td>['direct', 'offensive', 'hate']</td>\n",
       "      <td>en</td>\n",
       "      <td>ousidhoum2019en_with_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Que ce ne soit pas des Burundais refugie...</td>\n",
       "      <td>['none', 'indirect', 'hate']</td>\n",
       "      <td>en</td>\n",
       "      <td>ousidhoum2019en_with_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  If America had another 8 years of Obama's ideo...   \n",
       "1  Most Canadians have never met seen or associat...   \n",
       "2                         Hahaha grow up faggot @URL   \n",
       "3  @user queue is fucking retarded it makes every...   \n",
       "4  @user Que ce ne soit pas des Burundais refugie...   \n",
       "\n",
       "                                               label language  \\\n",
       "0  ['disrespectful', 'none', 'fearful', 'hate', '...       en   \n",
       "1                          ['offensive', 'indirect']       en   \n",
       "2                          ['offensive', 'indirect']       en   \n",
       "3                    ['direct', 'offensive', 'hate']       en   \n",
       "4                       ['none', 'indirect', 'hate']       en   \n",
       "\n",
       "                           source dataset  \n",
       "0  ousidhoum2019en_with_stopwords     NaN  \n",
       "1  ousidhoum2019en_with_stopwords     NaN  \n",
       "2  ousidhoum2019en_with_stopwords     NaN  \n",
       "3  ousidhoum2019en_with_stopwords     NaN  \n",
       "4  ousidhoum2019en_with_stopwords     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('formatted/merged.csv', index=False, sep='\\t')\n",
    "df = pd.read_csv('formatted/merged.csv', lineterminator='\\n', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f1ae146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'fr' 'it']\n",
      "text        163094\n",
      "label       163094\n",
      "language    163094\n",
      "source      163094\n",
      "dataset      27262\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.language.unique())\n",
    "print(df.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
